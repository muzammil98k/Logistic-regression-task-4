{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6840e",
   "metadata": {},
   "source": [
    "# Logistic Regression on Breast Cancer Dataset\n",
    "This notebook demonstrates binary classification using Logistic Regression.\n",
    "We will:\n",
    "1. Load and preprocess the dataset.\n",
    "2. Perform Train/Test split and standardize features.\n",
    "3. Fit Logistic Regression.\n",
    "4. Evaluate performance with confusion matrix, precision, recall, and ROC-AUC.\n",
    "5. Tune the threshold and explain the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64328cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"id\", \"Unnamed: 32\"], errors='ignore')\n",
    "\n",
    "# Encode target variable (M=1, B=0)\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69874033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(\"diagnosis\", axis=1)\n",
    "y = df[\"diagnosis\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train logistic regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44483573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Benign','Malignant'], yticklabels=['Benign','Malignant'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function: sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "print(\"Sigmoid(0) =\", sigmoid(0))\n",
    "print(\"Sigmoid(2) =\", sigmoid(2))\n",
    "print(\"Sigmoid(-2) =\", sigmoid(-2))\n",
    "\n",
    "# Threshold tuning example\n",
    "threshold = 0.3\n",
    "y_pred_custom = (y_prob >= threshold).astype(int)\n",
    "\n",
    "cm_custom = confusion_matrix(y_test, y_pred_custom)\n",
    "sns.heatmap(cm_custom, annot=True, fmt='d', cmap='Oranges', xticklabels=['Benign','Malignant'], yticklabels=['Benign','Malignant'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {threshold})\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred_custom))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
